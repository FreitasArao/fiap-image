# ADR 016 — Convenção de Logging Estruturado para Métricas e Observabilidade

| Campo      | Valor                |
|------------|----------------------|
| Status     | Aceito               |
| Data       | 2026-02-14           |
| Autor      | Arão Freitas         |

## Contexto

O projeto FIAPX já utiliza `PinoLoggerService` com injeção de contexto via `CorrelationStore` (AsyncLocalStorage) e atributos Datadog (`dd.trace_id`, `dd.span_id`, `dd.correlation_id`) no mixin do Pino. O plugin de logging do Elysia e o `AbstractSQSConsumer` emitem logs semi-estruturados com duração e status. Porém, os logs de negócio nos use cases e serviços permanecem livres em formato — cada desenvolvedor escolhe mensagens de texto variáveis e campos ad hoc, sem padronização.

### Problemas

1. **Impossibilidade de gerar métricas**: Sem campos padronizados, não é possível criar Log-based Metrics no Datadog (ex.: P99 de latência de criação de vídeo, taxa de sucesso de reconcile).
2. **Busca ineficiente**: Mensagens como `"Creating video"` vs `"Video created"` vs `"[ReconcileUpload] Starting reconciliation"` tornam impossível filtrar logs de forma confiável.
3. **Sem taxa de sucesso/falha**: Não há campo padronizado para indicar o resultado de uma operação (`status`).
4. **Sem latência por operação de negócio**: Apenas HTTP e SQS consumer registram duração; use cases (create video, generate upload URLs, complete upload, reconcile) não.
5. **Error tracking parcial**: Erros são logados como string (`error: result.error`) em vez do objeto estruturado que o Datadog espera (`error.message`, `error.kind`, `error.stack`).
6. **Contexto por prefixo em mensagem**: Uso de `[ReconcileUpload]`, `[SqsReconciler]` na mensagem em vez de campo `resource` para agrupamento.

### Exemplo antes

```typescript
this.logger.log('Creating video', {
  totalSize: params.totalSize,
  duration: params.duration,
  filename: params.filename,
  extension: params.extension,
});
// ... operação ...
this.logger.log('Video created', { video: video.id.value });
this.logger.error('Failed to create video', { error: result.error });
```

Problemas: sem `event` para filtrar, sem `status` para medir sucesso/falha, sem `duration` para percentis, erro como valor solto.

## Decisão

Adotar uma convenção de logging baseada em **eventos nomeados** com campos padronizados, tipada via tipo `LogEvent`, que permite extração automática de métricas no Datadog e alinhamento com o tipo existente `DatadogLogMeta` em `src/core/libs/logging/abstract-logger.ts`.

### Tipo LogEvent

```typescript
// src/core/libs/logging/log-event.ts (sugestão de localização)
export type LogEvent = {
  message: string;
  event: string;
  resource?: string;
  status?: 'success' | 'failure' | 'skipped';
  duration?: number;  // nanosegundos (padrão Datadog)
  error?: {
    message: string;
    kind: string;
    stack?: string;
  };
  [key: string]: unknown;
};
```

O projeto já utiliza **duração em nanosegundos** no transport para Datadog; o helper `msToNs(ms)` existe em `log.decorator.ts` e `elysia.ts`. Manter `duration` em ns evita inconsistência com o restante do código.

### Campos obrigatórios

#### message (string) — sempre

Descrição legível para humanos. Deve ser concisa e descrever **o que aconteceu**.

Exemplos: `'Create video request started'`, `'Video reconcile completed'`, `'GET /videos 200 45ms'`.

#### event (string) — sempre

Identificador único e estável da ação. Convenção: `domínio.entidade.ação`.

**HTTP** (ver `src/modules/logging/elysia.ts`):

- `http.request.received`
- `http.request.completed`
- `http.request.error`

**SQS** (ver `src/modules/messaging/sqs/abstract-sqs-consumer.ts`):

- `sqs.consumer.started`
- `sqs.message.received`
- `sqs.message.processed`
- `sqs.message.failed`
- `sqs.message.publish_failed`
- `sqs.message.publishing`
- `sqs.message.published`

**Vídeo (domínio)**:

- `video.create.started`
- `video.create.completed`
- `video.upload_urls.started`
- `video.upload_urls.completed`
- `video.upload.completed`
- `video.reconcile.started`
- `video.reconcile.completed`
- `video.status_change.completed`

**S3 / EventBridge**:

- `s3.multipart.received`
- `s3.multipart.completed`
- `eventbridge.event.published`
- `eventbridge.event.publish_failed`

**Decorator** (já existente em `log.decorator.ts`):

- `method.execution.start`
- `method.execution.end`

O `event` é a chave primária para métricas no Datadog (contagem, avg(duration) por event, etc.). Diferente de `message`, o `event` não deve mudar entre versões.

Convenção de nomes: **domínio** (sistema/camada) → **entidade** (recurso) → **ação** (started, completed, failed, received, etc.).

#### resource (string) — sempre

Nome da classe ou componente que emitiu o log. O tipo `DatadogLogMeta` já possui `component`; este ADR adota **resource** como nome do campo no payload do log para consistência com a convenção Datadog de recurso. Pode ser mapeado para `component` na serialização se desejado.

Exemplos: `CreateVideoUseCase`, `CompleteMultipartHandler`, `ReconcileUploadService`, `AbstractSQSConsumer`, `HttpServer`.

### Campos condicionais

#### status (enum) — em eventos de conclusão

Valores: `'success'`, `'failure'`, `'skipped'`. Usar em todo evento `*.completed` ou que represente fim de operação. Não usar em `*.started`, `*.received`, `*.publishing`.

#### duration (number) — em eventos de conclusão

Tempo em **nanosegundos** desde o início até a conclusão. Usar em todo `*.completed`. O projeto já utiliza `msToNs(performance.now() - startTime)` no consumer e no plugin HTTP.

#### error (object) — em eventos de falha

Objeto com os [campos reservados do Datadog](https://docs.datadoghq.com/logs/log_configuration/attributes_naming_convention/#source-code):

- `error.message` (string, obrigatório)
- `error.kind` (string, obrigatório)
- `error.stack` (string, opcional — incluir em erros inesperados)

O Pino já possui `serializers: { err: pino.stdSerializers.err }` em `pino-logger.ts`; ao passar um objeto `error` com `message`, `kind` e opcionalmente `stack`, a serialização para o JSON de log deve expor esses campos de forma que o Datadog os reconheça (Error Tracking, stack trace rendering).

### Atributos custom por domínio

Prefixar com o domínio para evitar colisões e facilitar facets no Datadog.

**HTTP** (já em uso em `elysia.ts`):

| Atributo              | Tipo   | Uso                    |
|-----------------------|--------|------------------------|
| `http.method`         | string | http.request.*         |
| `http.url`            | string | http.request.*         |
| `http.url_details.path` | string | http.request.*       |
| `http.status_code`    | number | http.request.completed |
| `network.client.ip`   | string | http.request.received  |

**SQS**:

| Atributo           | Tipo   | Uso                |
|--------------------|--------|--------------------|
| `sqs.queueUrl`     | string | sqs.message.*      |
| `sqs.messageId`    | string | sqs.message.*      |
| `sqs.eventType`     | string | sqs.message.*      |

**Vídeo**:

| Atributo        | Tipo   | Uso                    |
|-----------------|--------|------------------------|
| `video.id`     | string | video.*                |
| `video.status` | string | video.reconcile.*, video.status_change.* |
| `video.filename` | string | video.create.*       |
| `video.duration` | number | video.create.* (ms)  |
| `video.totalSize` | number | video.create.*       |
| `upload.id`    | string | video.upload.*        |
| `upload.partNumber` | number | video.upload_urls.* |
| `upload.totalParts` | number | video.upload.*   |
| `upload.uploadedParts` | number | video.upload.* |

**S3**:

| Atributo   | Tipo   | Uso                  |
|------------|--------|----------------------|
| `s3.bucket`| string | s3.multipart.*       |
| `s3.key`   | string | s3.multipart.*       |
| `s3.objectKey` | string | s3.multipart.*   |

**EventBridge**:

| Atributo                | Tipo   | Uso                        |
|-------------------------|--------|----------------------------|
| `eventbridge.source`    | string | eventbridge.event.*        |
| `eventbridge.detailType`| string | eventbridge.event.*        |

### Padrão de uso: par started/completed

Toda operação que pode falhar ou tem latência relevante deve seguir o par:

```typescript
async execute(params: CreateVideoUseCaseParams): Promise<Result<...>> {
  const startTime = performance.now();

  this.logger.log('Create video request started', {
    event: 'video.create.started',
    resource: 'CreateVideoUseCase',
    'video.filename': params.filename,
    'video.totalSize': params.totalSize,
  });

  try {
    // ... trabalho ...
    this.logger.log('Create video completed', {
      event: 'video.create.completed',
      resource: 'CreateVideoUseCase',
      status: 'success',
      duration: msToNs(performance.now() - startTime),
      'video.id': video.id.value,
    });
    return Result.ok(...);
  } catch (err) {
    this.logger.error('Create video failed', {
      event: 'video.create.completed',
      resource: 'CreateVideoUseCase',
      status: 'failure',
      duration: msToNs(performance.now() - startTime),
      error: {
        message: err instanceof Error ? err.message : String(err),
        kind: err instanceof Error ? err.constructor.name : 'Error',
        stack: err instanceof Error ? err.stack : undefined,
      },
      'video.filename': params.filename,
    });
    throw err;
  }
}
```

O mesmo evento `*.completed` para sucesso e falha permite uma única Log-based Metric de distribuição de latência; o campo `status` diferencia resultado.

### Campos injetados automaticamente

Injetados pelo `PinoLoggerService` (mixin e base) e pelo `CorrelationStore`:

| Campo               | Origem                    | Sempre presente?     |
|---------------------|---------------------------|-----------------------|
| `dd.trace_id`       | CorrelationStore / OTel   | Sim, quando em contexto |
| `dd.span_id`        | CorrelationStore / OTel   | Sim, quando em contexto |
| `dd.correlation_id`| CorrelationStore          | Sim, quando em contexto |
| `service`           | base Pino (DD_SERVICE)     | Sim                   |
| `env`               | base Pino (DD_ENV)         | Sim                   |
| `version`           | base Pino (DD_VERSION)     | Sim                   |

O contexto de correlação é preenchido pelo middleware em `src/modules/telemetry/correlation-context.ts` (HTTP) e pelo `AbstractSQSConsumer` ao processar mensagens com envelope (SQS).

### Métricas extraíveis

Com esta convenção, métricas podem ser criadas no Datadog sem alteração de código adicional:

**Latência (Log-based Metric tipo Distribution)**:

- Tempo de criação de vídeo: `@event:video.create.completed` + measure `@duration`
- Tempo de geração de URLs: `@event:video.upload_urls.completed` + measure `@duration`
- Tempo de reconcile: `@event:video.reconcile.completed` + measure `@duration`
- Latência HTTP por rota: `@event:http.request.completed` + measure `@duration` + group by `@http.url_details.path`
- Tempo de processamento SQS: `@event:sqs.message.processed` + measure `@duration`

**Taxa de sucesso/falha (Count)**:

- Taxa de sucesso de create video: `count(@event:video.create.completed @status:success) / count(@event:video.create.completed)`
- Taxa de falha SQS: `count(@event:sqs.message.failed) / count(@event:sqs.message.received)`

**Volume (Count)**:

- Throughput de create video: `count(@event:video.create.started)`
- Volume de mensagens SQS: `count(@event:sqs.message.received) group by @resource`

## Consequências

### Positivas

- Métricas no Datadog criadas via UI (Log-based Metrics), sem novo deploy para percentis e contagens.
- Error Tracking automático quando `error.message` e `error.kind` forem usados de forma consistente.
- Dashboards e monitors por domínio (video.*, sqs.*, http.*) com campos estáveis.
- Queries estáveis: o campo `event` é estável; mudanças em `message` não quebram monitors.
- Onboarding: novos desenvolvedores seguem o tipo `LogEvent` e o padrão started/completed.

### Negativas

- Logs mais verbosos: cada log exige pelo menos `message`, `event`, `resource`.
- Convenção deve ser mantida: novos eventos devem seguir `domínio.entidade.ação`.
- Custo de ingestão: mais campos por log; mitigado pelo valor das métricas extraídas.

## Alternativas consideradas

1. **Usar apenas APM spans para métricas**: Rejeitado porque nem toda operação gera span (ex.: handlers internos de use cases); Log-based Metrics permitem qualquer campo do log como facet sem instrumentação extra.
2. **Logging sem estrutura fixa, busca por texto**: Rejeitado porque impossibilita métricas automatizadas e buscas confiáveis.
3. **Event sourcing completo**: Rejeitado como overengineering para o objetivo atual (observabilidade, não reconstrução de estado).

## Referências

- [Datadog Log-based Metrics](https://docs.datadoghq.com/logs/logs_to_metrics/)
- [Datadog Standard Attributes](https://docs.datadoghq.com/logs/log_configuration/attributes_naming_convention/)
- [Datadog Error Tracking for Logs](https://docs.datadoghq.com/logs/error_tracking/)
- [ADR 002](02.md) — EventBridge + SQS para eventos S3
- [ADR 007](07.md) — Monitoramento de upload e eventos via EventBridge + SQS
- [ADR 008](08.md) — KEDA Workers + Lambda (notificações)
- [ADR 010](10.md) — Fluxo de eventos S3: SQS Consumer
- [ADR 014](14.md) — EventBridge → SNS → SQS: Fan-out
